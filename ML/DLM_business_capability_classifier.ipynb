{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "961e5868",
   "metadata": {},
   "source": [
    "\n",
    "# DLM — Business Capability Classifier (LightGBM & XGBoost)\n",
    "\n",
    "This notebook trains classification models to predict **`business_capability`** from file metadata and content fields in `final_data.xlsx`:\n",
    "\n",
    "Columns expected:\n",
    "\n",
    "| business_capability | extension | extension_family | file_exists | original_file_path | original_path_depth | original_path_keywords | file_size_bytes | content_text | content_word_count |\n",
    "\n",
    "**Outline**\n",
    "1. Setup (install/import)\n",
    "2. Load & quick sanity checks\n",
    "3. Train/validation split\n",
    "4. Preprocessing pipeline (categorical / numeric / text)\n",
    "5. Baselines (majority class & logistic regression)\n",
    "6. LightGBM & XGBoost training with cross-validation\n",
    "7. Evaluation (accuracy, F1, ROC-AUC-OVR, confusion matrix)\n",
    "8. Feature importances & top signals\n",
    "9. Save artifacts (models, encoders, metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcc0788",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If running locally and you don't have these installed, uncomment:\n",
    "# %pip install -q lightgbm xgboost imbalanced-learn\n",
    "# %pip install -q pandas openpyxl scikit-learn matplotlib numpy joblib\n",
    "\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, classification_report,\n",
    "    confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import joblib\n",
    "\n",
    "# Optional, models (handled with try/except so notebook can still run)\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "except Exception as e:\n",
    "    LGBMClassifier = None\n",
    "    print(\"⚠️ LightGBM not available. Install with `pip install lightgbm`.\")\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except Exception as e:\n",
    "    XGBClassifier = None\n",
    "    print(\"⚠️ XGBoost not available. Install with `pip install xgboost`.\")\n",
    "\n",
    "OUTPUT_DIR = Path(\"artifacts_dlm\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94c6c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "DATA_PATH = Path(\"final_data.xlsx\")\n",
    "assert DATA_PATH.exists(), f\"Could not find {DATA_PATH.resolve()}. Place final_data.xlsx next to this notebook.\"\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "\n",
    "expected_cols = [\n",
    "    \"business_capability\",\"extension\",\"extension_family\",\"file_exists\",\n",
    "    \"original_file_path\",\"original_path_depth\",\"original_path_keywords\",\n",
    "    \"file_size_bytes\",\"content_text\",\"content_word_count\"\n",
    "]\n",
    "missing = [c for c in expected_cols if c not in df.columns]\n",
    "assert not missing, f\"Missing columns: {missing}\"\n",
    "\n",
    "print(df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ffb683",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic sanity checks\n",
    "print(\"Target value counts:\")\n",
    "print(df['business_capability'].value_counts(dropna=False).head(20))\n",
    "\n",
    "# Drop rows with missing target\n",
    "df = df.dropna(subset=['business_capability']).copy()\n",
    "\n",
    "# Cast types\n",
    "df['file_exists'] = df['file_exists'].astype('boolean').astype('Int64')  # keep as numeric 0/1 later\n",
    "# Ensure numeric\n",
    "for col in ['original_path_depth','file_size_bytes','content_word_count']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "# Fill obvious empties for text\n",
    "for col in ['content_text','original_path_keywords','original_file_path']:\n",
    "    df[col] = df[col].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01171a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train / test split\n",
    "X = df.drop(columns=['business_capability'])\n",
    "y = df['business_capability'].astype(str)  # treat as labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd7b487",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Column groups\n",
    "numeric_features = ['original_path_depth','file_size_bytes','content_word_count']\n",
    "categorical_features = ['extension','extension_family','file_exists']\n",
    "text_features = {\n",
    "    'content_text': {'ngram_range': (1,2), 'min_df': 2, 'max_features': 100000},\n",
    "    'original_path_keywords': {'ngram_range': (1,2), 'min_df': 2, 'max_features': 50000},\n",
    "    'original_file_path': {'ngram_range': (1,2), 'min_df': 2, 'max_features': 50000},\n",
    "}\n",
    "\n",
    "# Helpers to select a single column for TfidfVectorizer\n",
    "def col_selector(column_name):\n",
    "    return FunctionTransformer(lambda X: X[column_name].astype(str).values, validate=False)\n",
    "\n",
    "text_transformers = []\n",
    "for col, params in text_features.items():\n",
    "    text_transformers.append(\n",
    "        (f\"tfidf__{col}\", Pipeline(steps=[\n",
    "            (f\"sel__{col}\", col_selector(col)),\n",
    "            (\"tfidf\", TfidfVectorizer(ngram_range=params['ngram_range'],\n",
    "                                      min_df=params['min_df'],\n",
    "                                      max_features=params['max_features']))\n",
    "        ]), list(X.columns))  # ColumnTransformer ignores this list; we select via FunctionTransformer\n",
    "    )\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]), numeric_features),\n",
    "        (\"cat\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                          (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))]), categorical_features),\n",
    "        *text_transformers\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    n_jobs=None\n",
    ")\n",
    "\n",
    "preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f95d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Baseline models\n",
    "dummy = Pipeline([(\"prep\", preprocess), (\"clf\", DummyClassifier(strategy=\"most_frequent\"))])\n",
    "logreg = Pipeline([(\"prep\", preprocess),\n",
    "                   (\"clf\", LogisticRegression(max_iter=200, n_jobs=None, multi_class=\"auto\"))])\n",
    "\n",
    "for name, model in [(\"Dummy\", dummy), (\"LogReg\", logreg)]:\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    f1w = f1_score(y_test, preds, average=\"weighted\")\n",
    "    print(f\"{name} — Acc: {acc:.4f}  |  F1-weighted: {f1w:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb31ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model_cv(model, X, y, cv_splits=5):\n",
    "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scoring = {\n",
    "        \"accuracy\": \"accuracy\",\n",
    "        \"f1_weighted\": \"f1_weighted\",\n",
    "        \"f1_macro\": \"f1_macro\"\n",
    "    }\n",
    "    out = cross_validate(model, X, y, cv=cv, scoring=scoring, n_jobs=None, return_estimator=False)\n",
    "    summary = {k: (np.mean(v), np.std(v)) for k, v in out.items() if k.startswith(\"test_\")}\n",
    "    return summary\n",
    "\n",
    "def pretty_print_cv(summary, label):\n",
    "    print(f\"\\n{label} (CV):\")\n",
    "    for metric, (m, s) in summary.items():\n",
    "        print(f\"  {metric.replace('test_','')}: {m:.4f} ± {s:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa8b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lgbm_results = None\n",
    "if LGBMClassifier is not None:\n",
    "    lgbm_pipe = Pipeline([\n",
    "        (\"prep\", preprocess),\n",
    "        (\"clf\", LGBMClassifier(\n",
    "            n_estimators=400,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=63,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=RANDOM_STATE,\n",
    "            objective=\"multiclass\"\n",
    "        ))\n",
    "    ])\n",
    "    lgbm_cv = evaluate_model_cv(lgbm_pipe, X_train, y_train, cv_splits=5)\n",
    "    pretty_print_cv(lgbm_cv, \"LightGBM\")\n",
    "    lgbm_pipe.fit(X_train, y_train)\n",
    "    lgbm_preds = lgbm_pipe.predict(X_test)\n",
    "    lgbm_proba = None\n",
    "    try:\n",
    "        lgbm_proba = lgbm_pipe.predict_proba(X_test)\n",
    "    except Exception:\n",
    "        pass\n",
    "    lgbm_results = {\n",
    "        \"accuracy\": accuracy_score(y_test, lgbm_preds),\n",
    "        \"f1_weighted\": f1_score(y_test, lgbm_preds, average=\"weighted\"),\n",
    "        \"f1_macro\": f1_score(y_test, lgbm_preds, average=\"macro\"),\n",
    "        \"report\": classification_report(y_test, lgbm_preds, output_dict=True)\n",
    "    }\n",
    "    if lgbm_proba is not None and len(np.unique(y)) > 2:\n",
    "        try:\n",
    "            lgbm_results[\"roc_auc_ovr\"] = roc_auc_score(y_test, lgbm_proba, multi_class=\"ovr\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    print(\"\\nLightGBM — Test metrics\")\n",
    "    print(f\"Acc: {lgbm_results['accuracy']:.4f} | F1-w: {lgbm_results['f1_weighted']:.4f} | F1-macro: {lgbm_results['f1_macro']:.4f}\")\n",
    "else:\n",
    "    print(\"Skipping LightGBM — not installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd73ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_results = None\n",
    "if XGBClassifier is not None:\n",
    "    xgb_pipe = Pipeline([\n",
    "        (\"prep\", preprocess),\n",
    "        (\"clf\", XGBClassifier(\n",
    "            n_estimators=600,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            objective=\"multi:softprob\",\n",
    "            eval_metric=\"mlogloss\",\n",
    "            tree_method=\"hist\",\n",
    "            random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "    xgb_cv = evaluate_model_cv(xgb_pipe, X_train, y_train, cv_splits=5)\n",
    "    pretty_print_cv(xgb_cv, \"XGBoost\")\n",
    "    xgb_pipe.fit(X_train, y_train)\n",
    "    xgb_preds = xgb_pipe.predict(X_test)\n",
    "    xgb_proba = None\n",
    "    try:\n",
    "        xgb_proba = xgb_pipe.predict_proba(X_test)\n",
    "    except Exception:\n",
    "        pass\n",
    "    xgb_results = {\n",
    "        \"accuracy\": accuracy_score(y_test, xgb_preds),\n",
    "        \"f1_weighted\": f1_score(y_test, xgb_preds, average=\"weighted\"),\n",
    "        \"f1_macro\": f1_score(y_test, xgb_preds, average=\"macro\"),\n",
    "        \"report\": classification_report(y_test, xgb_preds, output_dict=True)\n",
    "    }\n",
    "    if xgb_proba is not None and len(np.unique(y)) > 2:\n",
    "        try:\n",
    "            xgb_results[\"roc_auc_ovr\"] = roc_auc_score(y_test, xgb_proba, multi_class=\"ovr\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    print(\"\\nXGBoost — Test metrics\")\n",
    "    print(f\"Acc: {xgb_results['accuracy']:.4f} | F1-w: {xgb_results['f1_weighted']:.4f} | F1-macro: {xgb_results['f1_macro']:.4f}\")\n",
    "else:\n",
    "    print(\"Skipping XGBoost — not installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecec7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_cm(y_true, y_pred, title):\n",
    "    labels = np.unique(np.concatenate([y_true, y_pred]))\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    disp.plot(ax=ax, cmap=\"Blues\", colorbar=False, values_format='d')\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if 'lgbm_preds' in globals():\n",
    "    plot_cm(y_test, lgbm_preds, \"LightGBM — Confusion Matrix\")\n",
    "if 'xgb_preds' in globals():\n",
    "    plot_cm(y_test, xgb_preds, \"XGBoost — Confusion Matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_feature_names_from_ct(ct: ColumnTransformer, X_sample: pd.DataFrame):\n",
    "    # Works with sklearn >= 1.0\n",
    "    output_features = []\n",
    "    for name, trans, cols in ct.transformers_:\n",
    "        if name == 'remainder':\n",
    "            continue\n",
    "        if hasattr(trans, 'get_feature_names_out'):\n",
    "            if isinstance(cols, (list, tuple)):\n",
    "                try:\n",
    "                    feats = list(trans.get_feature_names_out(cols))\n",
    "                except Exception:\n",
    "                    feats = list(trans.get_feature_names_out())\n",
    "            else:\n",
    "                try:\n",
    "                    feats = list(trans.get_feature_names_out())\n",
    "                except Exception:\n",
    "                    feats = [str(cols)]\n",
    "            output_features.extend(feats)\n",
    "        elif isinstance(trans, Pipeline):\n",
    "            last = trans.steps[-1][1]\n",
    "            if hasattr(last, 'get_feature_names_out'):\n",
    "                try:\n",
    "                    feats = list(last.get_feature_names_out())\n",
    "                except Exception:\n",
    "                    feats = [name]\n",
    "                output_features.extend([f\"{name}__{f}\" for f in feats])\n",
    "            else:\n",
    "                output_features.extend([name])\n",
    "        else:\n",
    "            output_features.extend([name])\n",
    "    return output_features\n",
    "\n",
    "def top_importances(pipeline, model_key=\"clf\", top_k=25):\n",
    "    try:\n",
    "        model = pipeline.named_steps[model_key]\n",
    "        ct = pipeline.named_steps['prep']\n",
    "        feats = get_feature_names_from_ct(ct, X_train)\n",
    "        if hasattr(model, \"feature_importances_\"):\n",
    "            importances = model.feature_importances_\n",
    "            order = np.argsort(importances)[::-1][:top_k]\n",
    "            top = [(feats[i] if i < len(feats) else f\"f{i}\", float(importances[i])) for i in order]\n",
    "            return top\n",
    "    except Exception as e:\n",
    "        print(\"Feature importance extraction failed:\", e)\n",
    "    return []\n",
    "\n",
    "if LGBMClassifier is not None and 'lgbm_pipe' in globals():\n",
    "    top_lgbm = top_importances(lgbm_pipe, top_k=25)\n",
    "    if top_lgbm:\n",
    "        df_l = pd.DataFrame(top_lgbm, columns=[\"feature\",\"importance\"])\n",
    "        display(df_l)\n",
    "\n",
    "if XGBClassifier is not None and 'xgb_pipe' in globals():\n",
    "    top_xgb = top_importances(xgb_pipe, top_k=25)\n",
    "    if top_xgb:\n",
    "        df_x = pd.DataFrame(top_xgb, columns=[\"feature\",\"importance\"])\n",
    "        display(df_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cdbf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics_summary = {}\n",
    "\n",
    "if lgbm_results:\n",
    "    metrics_summary['LightGBM'] = {\n",
    "        k: (float(v) if not isinstance(v, dict) else v) for k, v in lgbm_results.items()\n",
    "    }\n",
    "    joblib.dump(lgbm_pipe, OUTPUT_DIR / \"dlm_lgbm_pipeline.joblib\")\n",
    "if xgb_results:\n",
    "    metrics_summary['XGBoost'] = {\n",
    "        k: (float(v) if not isinstance(v, dict) else v) for k, v in xgb_results.items()\n",
    "    }\n",
    "    joblib.dump(xgb_pipe, OUTPUT_DIR / \"dlm_xgb_pipeline.joblib\")\n",
    "\n",
    "# Flat CSV of headline metrics\n",
    "rows = []\n",
    "for model_name, res in metrics_summary.items():\n",
    "    row = {\"model\": model_name}\n",
    "    for k in [\"accuracy\",\"f1_weighted\",\"f1_macro\",\"roc_auc_ovr\"]:\n",
    "        row[k] = res.get(k, np.nan)\n",
    "    rows.append(row)\n",
    "pd.DataFrame(rows).to_csv(OUTPUT_DIR / \"dlm_model_report.csv\", index=False)\n",
    "\n",
    "with open(OUTPUT_DIR / \"dlm_model_report.json\",\"w\") as f:\n",
    "    json.dump(metrics_summary, f, indent=2)\n",
    "\n",
    "print(\"Saved artifacts to:\", OUTPUT_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c03498",
   "metadata": {},
   "source": [
    "\n",
    "### Handling class imbalance (optional)\n",
    "If your target classes are highly imbalanced, consider:\n",
    "- Using `class_weight='balanced'` in `LogisticRegression`\n",
    "- For LightGBM/XGBoost, tune parameters or use sample weights per class.\n",
    "- Try resampling (e.g., `imblearn`'s `RandomUnderSampler`/`SMOTE`) **inside** the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "print(\"Train class distribution:\", Counter(y_train))\n",
    "print(\"Test  class distribution:\", Counter(y_test))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
