{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca484b75",
   "metadata": {},
   "source": [
    "# 03 - Model Training & Evaluation\n",
    "\n",
    "This notebook loads the engineered datasets, composes classical machine learning pipelines, and compares several candidate models using consistent metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb326a5",
   "metadata": {},
   "source": [
    "## How to use\n",
    "1. Confirm that the previous notebooks have generated `train_dataset.csv`, `test_dataset.csv`, and `preprocessor.joblib`.\n",
    "2. Adjust the model list or evaluation settings if needed.\n",
    "3. Run the notebook to benchmark classical models and persist the best-performing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e638c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install additional modeling dependencies.\n",
    "# !pip install scikit-learn scipy joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eceec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a757de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Configuration\n",
    "# ---------------------------------------------------------------------------\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ARTIFACT_DIR = NOTEBOOK_DIR / 'artifacts'\n",
    "ARTIFACT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "TRAIN_DATA_PATH = ARTIFACT_DIR / 'train_dataset.csv'\n",
    "TEST_DATA_PATH = ARTIFACT_DIR / 'test_dataset.csv'\n",
    "PREPROCESSOR_PATH = ARTIFACT_DIR / 'preprocessor.joblib'\n",
    "MODEL_DIR = ARTIFACT_DIR / 'models'\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "TARGET_COLUMN = 'business_capability'\n",
    "FEATURE_COLUMNS = [\n",
    "    'content_text',\n",
    "    'path_keywords',\n",
    "    'extension',\n",
    "    'path_depth',\n",
    "    'original_path_depth',\n",
    "    'path_token_count',\n",
    "    'content_char_len',\n",
    "    'content_word_count',\n",
    "    'file_exists',\n",
    "]\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "CV_FOLDS = 5\n",
    "\n",
    "for required_path in [TRAIN_DATA_PATH, TEST_DATA_PATH, PREPROCESSOR_PATH]:\n",
    "    if not required_path.exists():\n",
    "        raise FileNotFoundError(f'Missing artifact: {required_path}. Run prior notebooks first.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dcec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_DATA_PATH)\n",
    "test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "\n",
    "X_train = train_df[FEATURE_COLUMNS]\n",
    "y_train = train_df[TARGET_COLUMN]\n",
    "X_test = test_df[FEATURE_COLUMNS]\n",
    "y_test = test_df[TARGET_COLUMN]\n",
    "\n",
    "base_preprocessor = joblib.load(PREPROCESSOR_PATH)\n",
    "print('Loaded artifacts:')\n",
    "print(f'  Train shape: {X_train.shape}')\n",
    "print(f'  Test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a2130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_models = {\n",
    "    'logistic_regression': LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        solver='saga',\n",
    "        n_jobs=None,\n",
    "        penalty='l2',\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_STATE,\n",
    "    ),\n",
    "    'linear_svc': LinearSVC(\n",
    "        class_weight='balanced',\n",
    "        max_iter=5000,\n",
    "        random_state=RANDOM_STATE,\n",
    "    ),\n",
    "    'decision_tree': DecisionTreeClassifier(\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=2,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_STATE,\n",
    "    ),\n",
    "    'random_forest': RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced_subsample',\n",
    "    ),\n",
    "    'gradient_boosting': GradientBoostingClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "    ),\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "evaluation_rows = []\n",
    "model_reports = {}\n",
    "\n",
    "for model_name, estimator in candidate_models.items():\n",
    "    print(f'\n",
    "Training model: {model_name}')\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', clone(base_preprocessor)),\n",
    "        ('classifier', estimator),\n",
    "    ])\n",
    "\n",
    "    cv_scores = cross_validate(\n",
    "        pipeline,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=cv,\n",
    "        scoring=['accuracy', 'f1_macro', 'f1_weighted'],\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    model_reports[model_name] = report\n",
    "\n",
    "    evaluation_rows.append({\n",
    "        'model': model_name,\n",
    "        'cv_accuracy_mean': cv_scores['test_accuracy'].mean(),\n",
    "        'cv_accuracy_std': cv_scores['test_accuracy'].std(),\n",
    "        'cv_macro_f1_mean': cv_scores['test_f1_macro'].mean(),\n",
    "        'cv_weighted_f1_mean': cv_scores['test_f1_weighted'].mean(),\n",
    "        'test_accuracy': accuracy_score(y_test, y_pred),\n",
    "        'test_macro_f1': report['macro avg']['f1-score'],\n",
    "        'test_weighted_f1': report['weighted avg']['f1-score'],\n",
    "    })\n",
    "\n",
    "    joblib.dump(pipeline, MODEL_DIR / f'{model_name}_pipeline.joblib')\n",
    "\n",
    "results_df = pd.DataFrame(evaluation_rows).sort_values(by='test_weighted_f1', ascending=False).reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7928ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = results_df.iloc[0]['model']\n",
    "print(f'Best model based on weighted F1: {best_model_name}')\n",
    "print('\n",
    "Classification report (test set):')\n",
    "print(pd.DataFrame(model_reports[best_model_name]).T)\n",
    "\n",
    "BEST_MODEL_PATH = MODEL_DIR / f'{best_model_name}_pipeline.joblib'\n",
    "print(f'Saved best model pipeline to {BEST_MODEL_PATH}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}